@article{Demsar2016BalancedMixture,
    title = {{A Balanced Mixture of Antagonistic Pressures Promotes the Evolution of Parallel Movement}},
    year = {2016},
    journal = {Scientific Reports},
    author = {Dem{\v{s}}ar, Jure and {\v{S}}trumbelj, Erik and Lebar Bajec, Iztok},
    volume = {6},
    doi = {10.1038/srep39428}
}

@article{Demsar2017LinguisticEvolution,
    title = {{Evolution of Collective Behaviour in an Artificial World Using Linguistic Fuzzy Rule-Based Systems}},
    year = {2017},
    journal = {PLoS ONE},
    author = {Dem{\v{s}}ar, Jure and Lebar Bajec, Iztok},
    number = {1},
    pages = {1--20},
    volume = {12},
    doi = {10.1371/journal.pone.0168876}
}
@misc{Prompt,
author = {Banghao C., Zhaofeng Z., Nicolas L., Shengxin Z},
title = {Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review},
howpublished = {\url{https://arxiv.org/pdf/2310.14735.pdf}},
note = {Accessed: Mar 2024},
year = {2024}
}
@misc{Zero,
author = {Kojima et al.},
title = {Large Language Models are Zero-Shot Reasoners},
howpublished = {\url{https://arxiv.org/pdf/2205.11916}},
note = {Accessed: Mar 2024},
year = {2024}
}
@misc{cot,
author = {Pandey P., Medium},
title = {Chain of Thought Prompting: Guiding LLMs Step-by-Step},
howpublished = {\url{https://medium.com/@pankaj_pandey/chain-of-thought-prompting-guiding-llms-step-by-step-e6eac32d02d8}},
note = {Accessed: Mar 2024},
year = {2024}
}
@misc{ps,
author = {Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim},
title = {Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models},
howpublished = {\url{https://doi.org/10.48550/arXiv.2305.04091}},
note = {Accessed: Mar 2024},
year = {2024}
}
@misc{mistral,
author = {Jiang et al},
title = {Mistral 7B},
howpublished = {\url{https://arxiv.org/pdf/2310.06825}},
note = {Accessed: May 2024},
year = {2024}
}
@misc{common,
author = {Talmor et al},
title = {CommonsenseQA},
howpublished = {\url{https://paperswithcode.com/dataset/commonsenseqa}},
note = {Accessed: May 2024},
year = {2024}
}

@inproceedings{lin-etal-2020-commongen,
    title = "{C}ommon{G}en: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
    author = "Lin, Bill Yuchen  and
      Zhou, Wangchunshu  and
      Shen, Ming  and
      Zhou, Pei  and
      Bhagavatula, Chandra  and
      Choi, Yejin  and
      Ren, Xiang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.165",
    doi = "10.18653/v1/2020.findings-emnlp.165",
    pages = "1823--1840"
}
@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
    archivePrefix = "arXiv",
    eprint        = "1811.00937",
    primaryClass  = "cs",
}


[7] Talmor et al: CommonsenseQA;
Dostopano na: \url{https://paperswithcode.com/dataset/commonsenseqa} [Dostopano Marec 2024]\newline
